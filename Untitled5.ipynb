{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9aT28wdA-F3-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pywt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Morlet wavelet activation function\n",
        "def morlet_wavelet(x, w=5.0):\n",
        "    return np.cos(w * x) * np.exp(-x**2 / 2)\n"
      ],
      "metadata": {
        "id": "QACGRnHq-2ld"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Keras Layer with Morlet wavelet activation\n",
        "class MorletWaveletLayer(Layer):\n",
        "    def __init__(self, output_dim, w=5.0, **kwargs):\n",
        "        self.output_dim = output_dim\n",
        "        self.w = w\n",
        "        super(MorletWaveletLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.kernel = self.add_weight(name='kernel',\n",
        "                                      shape=(input_shape[1], self.output_dim),\n",
        "                                      initializer='uniform',\n",
        "                                      trainable=True)\n",
        "        super(MorletWaveletLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        z = tf.matmul(x, self.kernel)\n",
        "        return tf.cos(self.w * z) * tf.exp(-tf.square(z) / 2)\n"
      ],
      "metadata": {
        "id": "eXEPaHcR-3Y4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a simple Wavelet Neural Network model\n",
        "def create_wnn(input_dim, output_dim):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.InputLayer(input_shape=(input_dim,)))\n",
        "    model.add(MorletWaveletLayer(10))  # Hidden layer with 10 units\n",
        "    model.add(tf.keras.layers.Dense(output_dim))  # Output layer\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Generate some synthetic data\n",
        "    X = np.random.rand(100, 10)  # 100 samples, 10 features\n",
        "    y = np.random.rand(100, 1)   # 100 target values\n",
        "\n",
        "    # Create the Wavelet Neural Network\n",
        "    wnn = create_wnn(input_dim=10, output_dim=1)\n",
        "\n",
        "    # Train the network\n",
        "    wnn.fit(X, y, epochs=50, batch_size=10)\n",
        "\n",
        "    # Predict using the trained model\n",
        "    predictions = wnn.predict(X)\n",
        "    print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4RYmx4B-7fX",
        "outputId": "030ceb62-82ea-4655-c443-ce0eeb82b18b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "10/10 [==============================] - 1s 4ms/step - loss: 1.8096\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0098\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4084\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2261\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2391\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2160\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1997\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1920\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1868\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1825\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1745\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1664\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1599\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1558\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1493\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1467\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1427\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1395\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1360\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1323\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1299\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1264\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1240\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1224\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1182\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1188\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1131\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1110\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1094\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1082\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1063\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1025\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1014\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1042\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1036\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0966\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0978\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0944\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0907\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0906\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0911\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0877\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0871\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0864\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0851\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0833\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0842\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0814\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0821\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0808\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "[[0.24458668]\n",
            " [0.3952964 ]\n",
            " [0.48796076]\n",
            " [0.5553837 ]\n",
            " [0.36920208]\n",
            " [0.5189434 ]\n",
            " [0.21475984]\n",
            " [0.47826082]\n",
            " [0.2529735 ]\n",
            " [0.3798998 ]\n",
            " [0.3779829 ]\n",
            " [0.5156677 ]\n",
            " [0.46140075]\n",
            " [0.51043063]\n",
            " [0.41866648]\n",
            " [0.4584713 ]\n",
            " [0.45428616]\n",
            " [0.2527971 ]\n",
            " [0.41927153]\n",
            " [0.32236382]\n",
            " [0.3839981 ]\n",
            " [0.6801371 ]\n",
            " [0.34492385]\n",
            " [0.60302824]\n",
            " [0.453694  ]\n",
            " [0.44861495]\n",
            " [0.22030596]\n",
            " [0.15034388]\n",
            " [0.32528675]\n",
            " [0.38382596]\n",
            " [0.5804072 ]\n",
            " [0.2832588 ]\n",
            " [0.5861333 ]\n",
            " [0.2097434 ]\n",
            " [0.31081343]\n",
            " [0.3049736 ]\n",
            " [0.1868968 ]\n",
            " [0.3538047 ]\n",
            " [0.58857256]\n",
            " [0.29206777]\n",
            " [0.5978731 ]\n",
            " [0.4546606 ]\n",
            " [0.38003504]\n",
            " [0.34576958]\n",
            " [0.5678138 ]\n",
            " [0.55027914]\n",
            " [0.33733523]\n",
            " [0.47349048]\n",
            " [0.36328912]\n",
            " [0.14090359]\n",
            " [0.3914945 ]\n",
            " [0.64693284]\n",
            " [0.44850397]\n",
            " [0.4958545 ]\n",
            " [0.43980324]\n",
            " [0.3428979 ]\n",
            " [0.683669  ]\n",
            " [0.36392123]\n",
            " [0.28555965]\n",
            " [0.5338579 ]\n",
            " [0.58640105]\n",
            " [0.47927582]\n",
            " [0.59006906]\n",
            " [0.38081926]\n",
            " [0.6401382 ]\n",
            " [0.45318776]\n",
            " [0.36490476]\n",
            " [0.41759568]\n",
            " [0.4622643 ]\n",
            " [0.30548483]\n",
            " [0.36283112]\n",
            " [0.16948257]\n",
            " [0.40718114]\n",
            " [0.35964888]\n",
            " [0.2007476 ]\n",
            " [0.4577664 ]\n",
            " [0.3760997 ]\n",
            " [0.28013325]\n",
            " [0.6510302 ]\n",
            " [0.44480664]\n",
            " [0.35736072]\n",
            " [0.67349285]\n",
            " [0.46218723]\n",
            " [0.31528056]\n",
            " [0.5107289 ]\n",
            " [0.44898129]\n",
            " [0.53705204]\n",
            " [0.5526981 ]\n",
            " [0.39701897]\n",
            " [0.5370181 ]\n",
            " [0.4915306 ]\n",
            " [0.20557919]\n",
            " [0.6552564 ]\n",
            " [0.34552103]\n",
            " [0.4157502 ]\n",
            " [0.56673586]\n",
            " [0.28398842]\n",
            " [0.53975385]\n",
            " [0.2760734 ]\n",
            " [0.30345577]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Define the Morlet wavelet activation function\n",
        "def morlet_wavelet(x, w=5.0):\n",
        "    return tf.cos(w * x) * tf.exp(-tf.square(x) / 2)\n",
        "\n",
        "# Custom Keras Layer with Morlet wavelet activation\n",
        "class MorletWaveletLayer(Layer):\n",
        "    def __init__(self, units, w=5.0, **kwargs):\n",
        "        super(MorletWaveletLayer, self).__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.w = w\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.kernel = self.add_weight(name='kernel',\n",
        "                                      shape=(input_shape[-1], self.units),\n",
        "                                      initializer='glorot_uniform',\n",
        "                                      trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z = tf.matmul(inputs, self.kernel)\n",
        "        return morlet_wavelet(z, self.w)\n",
        "\n",
        "# Create a simple Wavelet Neural Network model\n",
        "def create_wnn(input_dim, output_dim):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.InputLayer(input_shape=(input_dim,)),\n",
        "        MorletWaveletLayer(units=10),\n",
        "        tf.keras.layers.Dense(output_dim)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Firefly Algorithm for optimization\n",
        "class FireflyAlgorithm:\n",
        "    def __init__(self, func, lb, ub, dim, n_fireflies=20, max_iter=100, alpha=0.5, beta=0.2, gamma=1.0):\n",
        "        self.func = func\n",
        "        self.lb = lb\n",
        "        self.ub = ub\n",
        "        self.dim = dim\n",
        "        self.n_fireflies = n_fireflies\n",
        "        self.max_iter = max_iter\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def optimize(self):\n",
        "        fireflies = np.random.uniform(self.lb, self.ub, (self.n_fireflies, self.dim))\n",
        "        fitness = np.apply_along_axis(self.func, 1, fireflies)\n",
        "\n",
        "        best_firefly = fireflies[np.argmin(fitness)]\n",
        "        best_fitness = np.min(fitness)\n",
        "\n",
        "        for t in range(self.max_iter):\n",
        "            for i in range(self.n_fireflies):\n",
        "                for j in range(self.n_fireflies):\n",
        "                    if fitness[j] < fitness[i]:\n",
        "                        r = np.linalg.norm(fireflies[i] - fireflies[j])\n",
        "                        beta = self.beta * np.exp(-self.gamma * r ** 2)\n",
        "                        fireflies[i] += beta * (fireflies[j] - fireflies[i]) + self.alpha * (np.random.rand(self.dim) - 0.5)\n",
        "                        fireflies[i] = np.clip(fireflies[i], self.lb, self.ub)\n",
        "                        fitness[i] = self.func(fireflies[i])\n",
        "\n",
        "                        if fitness[i] < best_fitness:\n",
        "                            best_firefly = fireflies[i]\n",
        "                            best_fitness = fitness[i]\n",
        "\n",
        "            self.alpha *= 0.97  # Decrease alpha over time\n",
        "\n",
        "        return best_firefly, best_fitness\n",
        "\n",
        "# Define the objective function\n",
        "def objective_function(weights, model, X_train, y_train):\n",
        "    model.set_weights(weights)\n",
        "    predictions = model.predict(X_train)\n",
        "    return mean_squared_error(y_train, predictions)\n",
        "\n",
        "# Preprocess the dataset\n",
        "def preprocess_data(file_path):\n",
        "    data = pd.read_csv(file_path)\n",
        "    X = data.drop(columns=['ActualEffort'])\n",
        "    y = data['ActualEffort']\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    return train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Main script\n",
        "if __name__ == \"__main__\":\n",
        "    # Load and preprocess the dataset\n",
        "    X_train, X_test, y_train, y_test = preprocess_data('cocomo_dataset.csv')\n",
        "\n",
        "    # Create the Wavelet Neural Network model\n",
        "    input_dim = X_train.shape[1]\n",
        "    output_dim = 1\n",
        "    wnn = create_wnn(input_dim, output_dim)\n",
        "\n",
        "    # Initialize the Firefly Algorithm\n",
        "    firefly_optimizer = FireflyAlgorithm(\n",
        "        func=lambda weights: objective_function(weights, wnn, X_train, y_train),\n",
        "        lb=-1.0,\n",
        "        ub=1.0,\n",
        "        dim=wnn.count_params(),\n",
        "        n_fireflies=20,\n",
        "        max_iter=100\n",
        "    )\n",
        "\n",
        "    # Optimize the model weights using Firefly Algorithm\n",
        "    best_weights, best_fitness = firefly_optimizer.optimize()\n",
        "    wnn.set_weights(best_weights)\n",
        "\n",
        "    # Evaluate the optimized model\n",
        "    predictions = wnn.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, predictions)\n",
        "    print(f'Test Mean Squared Error: {mse}')\n",
        "\n",
        "    # Plot the results\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(y_test.values, label='Actual Effort')\n",
        "    plt.plot(predictions, label='Predicted Effort')\n",
        "    plt.legend()\n",
        "    plt.title('Wavelet Neural Network Predictions with Firefly Algorithm')\n",
        "    plt.xlabel('Sample')\n",
        "    plt.ylabel('Effort')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "KQyXnMFs_DGE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}